/* eslint-disable no-console */
import { streamText, generateText } from 'ai'
import { withAuth } from '@/lib/auth/middleware'
import { prisma } from '@/lib/prisma/client'
import { DEFAULT_MODEL, AVAILABLE_MODELS } from '@/lib/constants/models'
import { getActiveApiKey, recordApiKeyUsage } from '@/lib/api-key-manager'
import { createOpenAI } from '@ai-sdk/openai'
import { getEncoding } from 'js-tiktoken'

const encoding = getEncoding('cl100k_base')

function countTokens(text: string): number {
  try {
    return encoding.encode(text).length
  } catch (e) {
    console.warn('Token counting failed:', e)
    return 0
  }
}

// Î™®Îç∏Î≥Ñ Ï†úÍ≥µÏûê Îß§Ìïë Ï†úÍ±∞ (AVAILABLE_MODELSÏóêÏÑú Ï°∞Ìöå)

export const POST = withAuth(async (req: Request, userId: string) => {
  try {
    const { messages, conversationId, model = DEFAULT_MODEL, editMessageId, parentMessageId: clientParentMessageId } = await req.json()

    // Î™®Îç∏ ÏÑ§Ï†ï Ï°∞Ìöå (DB Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ Static)
    let modelConfig: any = await prisma.model.findUnique({
      where: { id: model },
      include: { apiKey: true }
    })

    // DBÏóê ÏóÜÏúºÎ©¥ Static List ÌôïÏù∏ (Legacy support)
    if (!modelConfig) {
      modelConfig = AVAILABLE_MODELS.find(m => m.id === model)
    }

    // Î™®Îç∏ Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨
    if (!modelConfig) {
      return new Response('Invalid model', { status: 400 })
    }

    // Ï†úÍ≥µÏûê ÌôïÏù∏
    const provider = modelConfig.provider

    // Ïä§Ìä∏Î¶¨Î∞ç ÏßÄÏõê Ïó¨Î∂Ä (DB Î™®Îç∏ÏùÄ ÌïÑÎìú ÏÇ¨Ïö©, TEXT/TEXT_VISIONÏùÄ Í∏∞Î≥∏ true)
    const modelType = modelConfig.type ?? 'TEXT'
    const supportsStreaming = modelConfig.supportsStreaming ??
      (modelType === 'TEXT' || modelType === 'TEXT_VISION')

    // API ÌÇ§ Í∞ÄÏ†∏Ïò§Í∏∞
    let apiKeyId: string | null = null
    let activeKeyApiKey: string | null = null
    let activeKeyBaseUrl: string | null = null

    try {
      // 1. Î™®Îç∏Ïóê Ïó∞Í≤∞Îêú ÌäπÏ†ï API KeyÍ∞Ä ÏûàÏúºÎ©¥ ÏÇ¨Ïö©
      if (modelConfig.apiKey) {
        if (!modelConfig.apiKey.isActive) {
          return new Response('Ïó∞Í≤∞Îêú API ÌÇ§Í∞Ä ÎπÑÌôúÏÑ±ÌôîÎêòÏóàÏäµÎãàÎã§.', { status: 500 })
        }

        // Decrypt key
        const { decryptApiKey, deserializeEncryptedData } = await import('@/lib/crypto')
        const encryptedData = deserializeEncryptedData(modelConfig.apiKey.encryptedKeyJson)

        apiKeyId = modelConfig.apiKey.id
        activeKeyApiKey = decryptApiKey(encryptedData)
        activeKeyBaseUrl = modelConfig.apiKey.baseUrl || null
      } else {
        // 2. ÏóÜÏúºÎ©¥ Î°úÎìúÎ∞∏Îü∞Ïã±/Í∏∞Î≥∏ ÌÇ§ Ï°∞Ìöå (Í∏∞Ï°¥ Î°úÏßÅ)
        const activeKey = await getActiveApiKey(provider)
        if (!activeKey) {
          return new Response(`${provider} API ÌÇ§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.`, { status: 500 })
        }
        apiKeyId = activeKey.id
        activeKeyApiKey = activeKey.apiKey
        activeKeyBaseUrl = activeKey.baseUrl || null
      }
    } catch (error) {
      console.error('API ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ± Ïã§Ìå®:', error)
      return new Response('API ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.', { status: 500 })
    }

    // Ïã§Ï†ú API Ìò∏Ï∂úÏóê ÏÇ¨Ïö©Ìï† Î™®Îç∏ ID
    // DB Î™®Îç∏Ïù∏ Í≤ΩÏö∞ apiModelId ÏÇ¨Ïö©, ÏïÑÎãàÎ©¥(static) model ID Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
    const apiModelId = modelConfig.apiModelId || modelConfig.id

    // Save user message to database
    let userMessageId: string | null = null
    let parentMessageIdForAssistant: string | null = null

    if (conversationId) {
      const lastMessage = messages[messages.length - 1];
      let contentToSave = '';

      if (typeof lastMessage.content === 'string') {
        contentToSave = lastMessage.content;
      } else if (Array.isArray(lastMessage.content)) {
        // Î©ÄÌã∞Î™®Îã¨ Î©îÏãúÏßÄ(Ïù¥ÎØ∏ÏßÄ Îì±)Îäî JSON Î¨∏ÏûêÏó¥Î°ú Ï†ÄÏû•
        contentToSave = JSON.stringify(lastMessage.content);
      }

      if (editMessageId) {
        // ÏàòÏ†ï Î™®Îìú: ÌòïÏ†ú Î©îÏãúÏßÄ ÏÉùÏÑ± (Í∞ôÏùÄ Î∂ÄÎ™® Î©îÏãúÏßÄ ID ÏÇ¨Ïö©)
        const originalMessage = await prisma.message.findUnique({
          where: { id: editMessageId }
        })

        if (originalMessage) {
          // ÏÉà ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÎ•º ÌòïÏ†úÎ°ú ÏÉùÏÑ± (Í∞ôÏùÄ parentMessageId)
          const newUserMessage = await prisma.message.create({
            data: {
              conversationId,
              role: 'user',
              content: contentToSave,
              parentMessageId: originalMessage.parentMessageId  // ÌòïÏ†ú Í¥ÄÍ≥Ñ!
            }
          })
          userMessageId = newUserMessage.id
          parentMessageIdForAssistant = newUserMessage.id
          console.log(`[EditMessage] Created sibling message ${userMessageId} (parent: ${originalMessage.parentMessageId})`)
        }
      } else {
        // ÏùºÎ∞ò Î™®Îìú: ÏÉà Î©îÏãúÏßÄ ÏÉùÏÑ± (Ìä∏Î¶¨ Íµ¨Ï°∞)
        const newUserMessage = await prisma.message.create({
          data: {
            conversationId,
            role: 'user',
            content: contentToSave,
            parentMessageId: clientParentMessageId || null  // ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú Ï†ÑÎã¨Î∞õÏùÄ Î∂ÄÎ™® ID
          }
        })
        userMessageId = newUserMessage.id
        parentMessageIdForAssistant = newUserMessage.id
      }
    }

    const startTime = Date.now()

    // Convert OpenAI 'image_url' format to Vercel AI SDK 'image' format
    const formattedMessages = messages.map((m: any) => {
      if (Array.isArray(m.content)) {
        return {
          ...m,
          content: m.content.map((c: any) => {
            if (c.type === 'image_url') {
              return {
                type: 'image',
                image: c.image_url.url
              }
            }
            return c
          })
        }
      }
      return m
    })

    const openaiProvider = createOpenAI({
      apiKey: activeKeyApiKey!,
      baseURL: activeKeyBaseUrl || undefined
    })
    /**
     * [Í≤¨Í≥†Ìïú Ïä§Ìä∏Î¶¨Î∞ç ÏïÑÌÇ§ÌÖçÏ≤ò - v1.5]
     * 
     * ‚ö†Ô∏è Ï§ëÏöî: Ïù¥ Î°úÏßÅÏùÄ ÏÉàÎ°úÍ≥†Ïπ®/ÌéòÏù¥ÏßÄ Ïù¥Îèô ÏãúÏóêÎèÑ Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµÏùÑ Î≥¥Ï°¥ÌïòÍ∏∞ ÏúÑÌïú ÌïµÏã¨ ÏΩîÎìúÏûÖÎãàÎã§!
     * 
     * Í∏∞Ï°¥ Î¨∏Ï†ú:
     * - Ïä§Ìä∏Î¶¨Î∞ç ÏôÑÎ£å ÌõÑÏóêÎßå DBÏóê Ï†ÄÏû•ÎêòÏñ¥, Ï§ëÍ∞ÑÏóê ÏÉàÎ°úÍ≥†Ïπ®ÌïòÎ©¥ ÏùëÎãµÏù¥ ÏòÅÍµ¨ ÏÜêÏã§Îê®
     * - ÏÉà Ï±ÑÌåÖ ÏÉùÏÑ± ÌõÑ router.push() Ïãú ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉÅÌÉúÏôÄ DBÍ∞Ä ÎèôÍ∏∞ÌôîÎêòÏßÄ ÏïäÏùå
     * 
     * Ìï¥Í≤∞ Î∞©Î≤ï:
     * 1. Ïä§Ìä∏Î¶¨Î∞ç ÏãúÏûë Ï†ÑÏóê Îπà Î©îÏãúÏßÄÎ•º DBÏóê ÎØ∏Î¶¨ ÏÉùÏÑ± (isStreaming: true)
     * 2. ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä Ïñ∏Ï†úÎì† DBÏóêÏÑú ÌòÑÏû¨ ÏßÑÌñâ ÏÉÅÌÉúÎ•º Ï°∞Ìöå Í∞ÄÎä•
     * 3. Ïä§Ìä∏Î¶¨Î∞ç ÏôÑÎ£å Ïãú Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ (isStreaming: false)
     * 
     * üö´ Ïù¥ Î°úÏßÅÏùÑ ÏàòÏ†ïÌï† Îïå Ï£ºÏùòÏÇ¨Ìï≠:
     * - prisma.message.createÍ∞Ä streamTextÎ≥¥Îã§ Î®ºÏ†Ä Ìò∏Ï∂úÎêòÏñ¥Ïïº Ìï®
     * - assistantMessageIdÍ∞Ä onFinishÏóêÏÑú ÏÇ¨Ïö©ÎêòÎØÄÎ°ú ÌÅ¥Î°úÏ†ÄÏóê Ï∫°Ï≤òÎê®
     * - isStreaming ÌïÑÎìúÎäî ÌîÑÎ°†Ìä∏ÏóîÎìú polling Î°úÏßÅÍ≥º Ïó∞ÎèôÎê®
     */
    if (supportsStreaming) {
      let assistantContent = ''
      let assistantMessageId: string | null = null

      // [Step 1] Ïä§Ìä∏Î¶¨Î∞ç ÏãúÏûë Ï†Ñ Îπà assistant Î©îÏãúÏßÄ ÎØ∏Î¶¨ ÏÉùÏÑ±
      // - ÏÉàÎ°úÍ≥†Ïπ® Ïãú ÌîÑÎ°†Ìä∏ÏóîÎìúÍ∞Ä DBÏóêÏÑú Ïù¥ Î©îÏãúÏßÄÎ•º Ï°∞ÌöåÌïòÏó¨ Î≥µÍµ¨ Í∞ÄÎä•
      // - isStreaming: trueÎ°ú ÏÑ§Ï†ïÌïòÏó¨ "ÏïÑÏßÅ ÏùëÎãµ Ï§ë"ÏûÑÏùÑ ÌëúÏãú
      if (conversationId) {
        const assistantMessage = await prisma.message.create({
          data: {
            conversationId,
            role: 'assistant',
            content: '',
            isStreaming: true,
            parentMessageId: parentMessageIdForAssistant  // ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÎ•º Î∂ÄÎ™®Î°ú ÏÑ§Ï†ï
          }
        })
        assistantMessageId = assistantMessage.id
      }

      const result = await streamText({
        model: openaiProvider(apiModelId),
        messages: formattedMessages,
        abortSignal: req.signal,
        onFinish: async ({ usage }) => {
          const responseTime = Date.now() - startTime

          // [Step 3] Ïä§Ìä∏Î¶¨Î∞ç ÏôÑÎ£å: Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ (CREATE ‚Üí UPDATE Ìå®ÌÑ¥)
          // - isStreaming: falseÎ°ú Î≥ÄÍ≤ΩÌïòÏó¨ ÏôÑÎ£å ÌëúÏãú
          // - ÌîÑÎ°†Ìä∏ÏóîÎìú pollingÏù¥ Ïù¥Î•º Í∞êÏßÄÌïòÍ≥† polling Ï§ëÏßÄ
          if (assistantMessageId) {
            await prisma.message.update({
              where: { id: assistantMessageId },
              data: {
                content: assistantContent,
                isStreaming: false,
                tokens: usage?.totalTokens,
              }
            })
          }

          // Log token usage
          console.log('[TokenUsage] Stream finished. Usage:', usage)


          if (usage || assistantContent) {
            let promptTokens = usage ? (usage as any).promptTokens ?? 0 : 0
            let completionTokens = usage ? (usage as any).completionTokens ?? 0 : 0

            // Fallback: Calculate manually if usage is missing
            if (promptTokens === 0 && completionTokens === 0) {
              console.warn('[TokenUsage] Usage data missing, calculating manually...')
              // Calculate prompt tokens from messages
              const promptText = messages.map((m: any) => {
                if (typeof m.content === 'string') return m.content
                return m.content.filter((p: any) => p.type === 'text').map((p: any) => p.text).join('\n')
              }).join('\n')
              promptTokens = countTokens(promptText)
              // Calculate completion tokens from accumulated content
              completionTokens = countTokens(assistantContent)
            }

            await prisma.tokenUsage.create({
              data: {
                userId,
                model,
                promptTokens,
                completionTokens,
              }
            })
            console.log(`[TokenUsage] Saved: ${promptTokens}p, ${completionTokens}c (Source: ${usage ? 'Provider' : 'Manual'})`)
          } else {
            console.warn('[TokenUsage] No usage data available from stream')
          }

          // API ÌÇ§ ÏÇ¨Ïö© Í∏∞Î°ù (Ïò§Î•ò Ïó¨Î∂ÄÏóê Í¥ÄÍ≥ÑÏóÜÏù¥ Í∏∞Î°ù)
          if (apiKeyId) {
            try {
              await recordApiKeyUsage({
                apiKeyId,
                endpoint: '/api/chat',
                model,
                tokens: usage?.totalTokens ?? 0,
                status: 'success',
                responseTime,
                errorMessage: undefined
              })
            } catch (usageError) {
              console.error('API ÌÇ§ ÏÇ¨Ïö© Í∏∞Î°ù Ïã§Ìå®:', usageError)
            }
          }
        },
        onChunk: ({ chunk }) => {
          // Accumulate the content for database storage
          if (chunk.type === 'text-delta') {
            assistantContent += (chunk as any).value ?? (chunk as any).text ?? ''
          }
        },
      })

      // ÏùëÎãµ Ìó§ÎçîÏóê ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ ID Ìè¨Ìï®
      const streamResponse = result.toTextStreamResponse()
      if (userMessageId) {
        const headers = new Headers(streamResponse.headers)
        headers.set('X-User-Message-Id', userMessageId)
        return new Response(streamResponse.body, {
          status: streamResponse.status,
          statusText: streamResponse.statusText,
          headers
        })
      }
      return streamResponse
    }

    // ÎπÑÏä§Ìä∏Î¶¨Î∞ç Î™®Îìú (Ï†ÑÏ≤¥ ÏùëÎãµ ÏôÑÎ£å ÌõÑ Ï†ÑÏÜ°)
    const result = await generateText({
      model: openaiProvider(apiModelId),
      messages: formattedMessages,
      abortSignal: req.signal,
    })

    const responseTime = Date.now() - startTime
    const assistantContent = result.text
    const usage = result.usage

    console.log('[TokenUsage] Non-streaming usage:', usage)

    // Save assistant message to database
    if (conversationId) {
      await prisma.message.create({
        data: {
          conversationId,
          role: 'assistant',
          content: assistantContent,
          tokens: usage?.totalTokens,
        }
      })
    }

    // Log token usage
    // Log token usage
    if (usage || assistantContent) {
      let promptTokens = usage ? (usage as any).promptTokens ?? 0 : 0
      let completionTokens = usage ? (usage as any).completionTokens ?? 0 : 0

      // Fallback: Calculate manually if usage is missing
      if (promptTokens === 0 && completionTokens === 0) {
        console.warn('[TokenUsage] Usage data missing (non-stream), calculating manually...')
        // Calculate prompt tokens from messages
        const promptText = messages.map((m: any) => {
          if (typeof m.content === 'string') return m.content
          return m.content.filter((p: any) => p.type === 'text').map((p: any) => p.text).join('\n')
        }).join('\n')
        promptTokens = countTokens(promptText)
        completionTokens = countTokens(assistantContent)
      }

      await prisma.tokenUsage.create({
        data: {
          userId,
          model,
          promptTokens,
          completionTokens,
        }
      })
      console.log(`[TokenUsage] Saved: ${promptTokens}p, ${completionTokens}c (Source: ${usage ? 'Provider' : 'Manual'})`)
    } else {
      console.warn('[TokenUsage] No usage data available from non-streaming')
    }

    // API ÌÇ§ ÏÇ¨Ïö© Í∏∞Î°ù
    if (apiKeyId) {
      try {
        await recordApiKeyUsage({
          apiKeyId,
          endpoint: '/api/chat',
          model,
          tokens: usage?.totalTokens ?? 0,
          status: 'success',
          responseTime,
          errorMessage: undefined
        })
      } catch (usageError) {
        console.error('API ÌÇ§ ÏÇ¨Ïö© Í∏∞Î°ù Ïã§Ìå®:', usageError)
      }
    }

    // JSON ÏùëÎãµ Î∞òÌôò (ÎπÑÏä§Ìä∏Î¶¨Î∞ç)
    return new Response(JSON.stringify({
      content: assistantContent,
      usage: usage ? {
        promptTokens: (usage as any).promptTokens,
        completionTokens: (usage as any).completionTokens,
        totalTokens: (usage as any).totalTokens,
      } : null,
    }), {
      headers: {
        'Content-Type': 'application/json',
      },
    })
  } catch (error) {
    console.error('Chat API error:', error)
    return new Response('Internal server error', { status: 500 })
  }
})

